{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# スラックにあった元になるやつ"
      ],
      "metadata": {
        "id": "_XvHYm3o7LYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# load data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# preprocessing\n",
        "cat_cols = [\"region\", \"manufacturer\", \"condition\", \"fuel\", \"title_status\", \"cylinders\",\n",
        "            \"transmission\", \"drive\", \"size\", \"type\", \"paint_color\", \"state\"]\n",
        "\n",
        "## cat -> count encoding\n",
        "def count_encoder(df, cat_cols):\n",
        "    for col in cat_cols:\n",
        "        count_map = df[col].value_counts().to_dict()\n",
        "        df[col+'_count'] = df[col].map(count_map)\n",
        "    df = df.drop(columns=cat_cols)  # この行を追加\n",
        "    return df\n",
        "\n",
        "cat_cols = [\"region\", \"manufacturer\", \"condition\", \"fuel\", \"title_status\", \"cylinders\",\n",
        "            \"transmission\", \"drive\", \"size\", \"type\", \"paint_color\", \"state\"]\n",
        "\n",
        "\n",
        "## target log transform\n",
        "def log_trainsform(df, cols):\n",
        "    return df[cols]\n",
        "\n",
        "train_df = count_encoder(train_df, cat_cols)\n",
        "test_df = count_encoder(test_df, cat_cols)\n",
        "\n",
        "# model\n",
        "features = [c for c in train_df.columns if c not in [\"id\", \"price\"]]\n",
        "target = train_df[\"price\"]\n",
        "\n",
        "param = {\n",
        "    'bagging_freq': 5,\n",
        "    'bagging_fraction': 0.4,\n",
        "    'boost_from_average':'false',\n",
        "    'boost': 'gbdt',\n",
        "    'feature_fraction': 0.05,\n",
        "    'learning_rate': 0.01,\n",
        "    'max_depth': -1,\n",
        "    'metric':'mape',\n",
        "    'min_data_in_leaf': 80,\n",
        "    'min_sum_hessian_in_leaf': 10.0,\n",
        "    'num_leaves': 13,\n",
        "    'num_threads': 8,\n",
        "    'tree_learner': 'serial',\n",
        "    'objective': 'regression',\n",
        "    'verbosity': -1\n",
        "}\n",
        "\n",
        "folds = KFold(n_splits=10, shuffle=True, random_state=44000)\n",
        "oof = np.zeros(len(train_df))\n",
        "predictions = np.zeros(len(test_df))\n",
        "feature_importance_df = pd.DataFrame()\n",
        "\n",
        "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
        "    print(\"Fold {}\".format(fold_+1))\n",
        "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
        "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
        "\n",
        "    num_round = 1000000\n",
        "    rgl = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data],\n",
        "                    callbacks=[lgb.early_stopping(stopping_rounds=3000, verbose=True),\n",
        "                               lgb.log_evaluation(1000)]\n",
        "                   )\n",
        "    oof[val_idx] = rgl.predict(train_df.iloc[val_idx][features], num_iteration=rgl.best_iteration)\n",
        "\n",
        "    fold_importance_df = pd.DataFrame()\n",
        "    fold_importance_df[\"Feature\"] = features\n",
        "    fold_importance_df[\"importance\"] = rgl.feature_importance()\n",
        "    fold_importance_df[\"fold\"] = fold_ + 1\n",
        "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
        "\n",
        "    predictions += rgl.predict(test_df[features], num_iteration=rgl.best_iteration) / folds.n_splits\n",
        "\n",
        "print(\"CV score: {:<8.5f}\".format(mean_absolute_percentage_error(target, oof)))\n",
        "\n",
        "# submission file\n",
        "sub_df = pd.DataFrame({\"id\":test_df[\"id\"].values})\n",
        "sub_df[\"price\"] = np.exp(predictions)\n",
        "sub_df.to_csv(\"baseline_lgbm.csv\", index=False, header=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxqd1D2iU1WB",
        "outputId": "ed0e6bcc-271f-47b0-fd45-3fef4fd2ead8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Training until validation scores don't improve for 3000 rounds\n",
            "[1000]\ttraining's mape: 0.740155\tvalid_1's mape: 0.752806\n",
            "[2000]\ttraining's mape: 0.691491\tvalid_1's mape: 0.703225\n",
            "[3000]\ttraining's mape: 0.684692\tvalid_1's mape: 0.699574\n",
            "Early stopping, best iteration is:\n",
            "[57]\ttraining's mape: 0.541383\tvalid_1's mape: 0.54458\n",
            "Fold 2\n",
            "Training until validation scores don't improve for 3000 rounds\n",
            "[1000]\ttraining's mape: 0.744675\tvalid_1's mape: 0.728355\n",
            "[2000]\ttraining's mape: 0.69422\tvalid_1's mape: 0.688016\n",
            "[3000]\ttraining's mape: 0.685102\tvalid_1's mape: 0.680442\n",
            "Early stopping, best iteration is:\n",
            "[57]\ttraining's mape: 0.542759\tvalid_1's mape: 0.530057\n",
            "Fold 3\n",
            "Training until validation scores don't improve for 3000 rounds\n",
            "[1000]\ttraining's mape: 0.742013\tvalid_1's mape: 0.740035\n",
            "[2000]\ttraining's mape: 0.693107\tvalid_1's mape: 0.698728\n",
            "[3000]\ttraining's mape: 0.685859\tvalid_1's mape: 0.693717\n",
            "Early stopping, best iteration is:\n",
            "[57]\ttraining's mape: 0.542408\tvalid_1's mape: 0.532016\n",
            "Fold 4\n",
            "Training until validation scores don't improve for 3000 rounds\n",
            "[1000]\ttraining's mape: 0.741355\tvalid_1's mape: 0.743153\n",
            "[2000]\ttraining's mape: 0.692864\tvalid_1's mape: 0.697043\n",
            "[3000]\ttraining's mape: 0.684316\tvalid_1's mape: 0.689579\n",
            "Early stopping, best iteration is:\n",
            "[57]\ttraining's mape: 0.541751\tvalid_1's mape: 0.539756\n",
            "Fold 5\n",
            "Training until validation scores don't improve for 3000 rounds\n",
            "[1000]\ttraining's mape: 0.743188\tvalid_1's mape: 0.750946\n",
            "[2000]\ttraining's mape: 0.691793\tvalid_1's mape: 0.707276\n",
            "[3000]\ttraining's mape: 0.685998\tvalid_1's mape: 0.703377\n",
            "Early stopping, best iteration is:\n",
            "[54]\ttraining's mape: 0.542637\tvalid_1's mape: 0.539516\n",
            "Fold 6\n",
            "Training until validation scores don't improve for 3000 rounds\n",
            "[1000]\ttraining's mape: 0.741307\tvalid_1's mape: 0.74929\n",
            "[2000]\ttraining's mape: 0.692289\tvalid_1's mape: 0.699439\n",
            "[3000]\ttraining's mape: 0.685359\tvalid_1's mape: 0.695208\n",
            "Early stopping, best iteration is:\n",
            "[57]\ttraining's mape: 0.540156\tvalid_1's mape: 0.551437\n",
            "Fold 7\n",
            "Training until validation scores don't improve for 3000 rounds\n",
            "[1000]\ttraining's mape: 0.744177\tvalid_1's mape: 0.732852\n",
            "[2000]\ttraining's mape: 0.695479\tvalid_1's mape: 0.687417\n",
            "[3000]\ttraining's mape: 0.686965\tvalid_1's mape: 0.681759\n",
            "Early stopping, best iteration is:\n",
            "[57]\ttraining's mape: 0.542605\tvalid_1's mape: 0.531228\n",
            "Fold 8\n",
            "Training until validation scores don't improve for 3000 rounds\n",
            "[1000]\ttraining's mape: 0.741297\tvalid_1's mape: 0.740797\n",
            "[2000]\ttraining's mape: 0.692556\tvalid_1's mape: 0.69151\n",
            "[3000]\ttraining's mape: 0.684646\tvalid_1's mape: 0.683589\n",
            "Early stopping, best iteration is:\n",
            "[57]\ttraining's mape: 0.540677\tvalid_1's mape: 0.549546\n",
            "Fold 9\n",
            "Training until validation scores don't improve for 3000 rounds\n",
            "[1000]\ttraining's mape: 0.738926\tvalid_1's mape: 0.769422\n",
            "[2000]\ttraining's mape: 0.691174\tvalid_1's mape: 0.715494\n",
            "[3000]\ttraining's mape: 0.683157\tvalid_1's mape: 0.705873\n",
            "Early stopping, best iteration is:\n",
            "[57]\ttraining's mape: 0.54074\tvalid_1's mape: 0.550586\n",
            "Fold 10\n",
            "Training until validation scores don't improve for 3000 rounds\n",
            "[1000]\ttraining's mape: 0.742129\tvalid_1's mape: 0.748603\n",
            "[2000]\ttraining's mape: 0.693355\tvalid_1's mape: 0.694383\n",
            "[3000]\ttraining's mape: 0.685621\tvalid_1's mape: 0.685399\n",
            "Early stopping, best iteration is:\n",
            "[54]\ttraining's mape: 0.541747\tvalid_1's mape: 0.547937\n",
            "CV score: 0.54167 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Q7TSFB5q2EZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "mape = mean_absolute_percentage_error(target, oof)\n",
        "print(f\"CV score (MAPE): {mape:<8.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsoB_BzHU18L",
        "outputId": "f4b43b9d-b154-49f5-b741-cf9d65d12196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score (MAPE): 0.54167 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a5rLO_FRY0Ow"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}